### **Задание 1: Введение в ETL и основы работы с данными**

**Цель занятия:**  
Познакомиться с базовыми концепциями ETL, ELT, показать, как данные перемещаются между системами,
и зачем нужны аналитические витрины. Подготовить инфраструктуру для дальнейшей работы.

[Ссылка на презентацию](https://docs.google.com/presentation/d/1XA4tuwNVk8zJ284__AaF7rGKKXbYw9GNX4vZ4QSA3-0/edit?slide=id.g32c9a3daff5_1_2#slide=id.g32c9a3daff5_1_2)  

**План занятия:**

1. **Теоретическая часть:**
    - Что такое ELT и зачем он нужен.
    - Типы данных: операционные (OLTP) и аналитические (OLAP).
    - Зачем нужны аналитические витрины и как они помогают в анализе данных.
    - Краткий обзор инструментов: DBT, Airflow, Elementary, Docker.

2. **Задание до 2025-12-06:**
    - Поднять локальную среду с помощью `docker-compose`:
        - PostgreSQL (как целевая база для аналитических данных).
        - MongoDB (как источник данных для "продового приложения").
        - Airflow для управления процессами.
    - Создать простое Python-приложение, которое записывает данные в MongoDB (например, качество
      воздуха, температуру и влажность).
    - Проверить, что приложение работает и данные записываются.
    - Развернуть приложение и среду на сервере.
    - Настроить Airflow для выполнения EL-процесса:
        - Извлечение данных из MongoDB.
        - Загрузка данных в PostgreSQL.
    - Проверить, что данные успешно перенесены в PostgreSQL.

3. **Артефакты:**
    - Выбран кейс для курса.
    - Один / два Git-репозитория:
        1. Сервис: Python-приложение, которое пишет в MongoDB.
        2. EL-пайплайн: Airflow ~~и DBT (опционально)~~ для обработки данных.
    - Рабочее приложение, которое записывает данные в MongoDB.
    - EL процесс, который переносит данные из MongoDB в PostgreSQL.
    - Ссылка на Airflow где можно посмотреть на работу регулярных тасок по генерации нагрузки на
      python сервис и переносу данных в Postgres.
   